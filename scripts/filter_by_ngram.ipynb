{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0f5f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "AI_TOOL = 'chatgpt' # copilot/chatgpt\n",
    "\n",
    "valid_engram_path = './' + AI_TOOL + '_ngrams.txt' # put here the correct path\n",
    "\n",
    "# get valid ngram from file\n",
    "VALID_NGRAMS = [line.strip() for line in open(valid_engram_path, 'r') if line.strip() != '']\n",
    "print(len(VALID_NGRAMS))\n",
    "\n",
    "def match_valid_ngrams(ngrams_list):\n",
    "    matched_ngrams = []\n",
    "    for elem in ngrams_list:\n",
    "        if elem in VALID_NGRAMS: matched_ngrams.append(elem)\n",
    "    return matched_ngrams\n",
    "\n",
    "def save_data(filename, elements):\n",
    "    with open(filename, 'w') as file:\n",
    "        for elem in elements:\n",
    "            file.write(json.dumps(elem) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c04bde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "commit_elements = []\n",
    "pr_elements = []\n",
    "issue_elements = []\n",
    "\n",
    "with open('commits_' + AI_TOOL + '.jsonl') as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.strip()\n",
    "        commit_elements.append(line)\n",
    "\n",
    "with open('issues_' + AI_TOOL + '.jsonl') as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.strip()\n",
    "        issue_elements.append(line)\n",
    "\n",
    "with open('pull-requests_' + AI_TOOL + '.jsonl') as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.strip()\n",
    "        pr_elements.append(line)\n",
    "\n",
    "print(f\"commits: {len(commit_elements)}\")\n",
    "print(f\"prs: {len(pr_elements)}\")\n",
    "print(f\"issues: {len(issue_elements)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9d366b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get only instances featuring valid ngrams\n",
    "count = 0\n",
    "\n",
    "valid_issue_instances = []\n",
    "valid_commit_instances = []\n",
    "valid_pr_instances = []\n",
    "\n",
    "no_ngrams_found_issue = []\n",
    "no_ngrams_found_commit = []\n",
    "no_ngrams_found_pr = []\n",
    "\n",
    "for issue,commit,pr in zip(issue_elements,commit_elements,pr_elements):\n",
    "    count+=1\n",
    "    issue = json.loads(issue)\n",
    "    commit = json.loads(commit)\n",
    "    pr = json.loads(pr)\n",
    "    ngrams_issue = issue['ngrams']\n",
    "    ngrams_commit = commit['ngrams']\n",
    "    ngrams_pr = pr['ngrams']\n",
    "\n",
    "    if len(ngrams_issue) == 0: no_ngrams_found_issue.append(issue)\n",
    "    if len(ngrams_commit) == 0: no_ngrams_found_commit.append(commit)\n",
    "    if len(ngrams_pr) == 0: no_ngrams_found_pr.append(pr)\n",
    "\n",
    "    if len(ngrams_issue) == 0 and len(ngrams_commit) == 0 and len(ngrams_pr) == 0: continue\n",
    "\n",
    "    ngrams_issue = [' '.join(tokens) for tokens in ngrams_issue]\n",
    "    ngrams_commit = [' '.join(tokens) for tokens in ngrams_commit]\n",
    "    ngrams_pr = [' '.join(tokens) for tokens in ngrams_pr]\n",
    "\n",
    "    # issue\n",
    "    matched_ngrams = match_valid_ngrams(ngrams_issue)\n",
    "    if len(matched_ngrams) > 0:\n",
    "        issue['valid_ngrams'] = matched_ngrams\n",
    "        valid_issue_instances.append(issue)\n",
    "    \n",
    "    # commit\n",
    "    matched_ngrams = match_valid_ngrams(ngrams_commit)\n",
    "    if len(matched_ngrams) > 0:\n",
    "        commit['valid_ngrams'] = matched_ngrams\n",
    "        valid_commit_instances.append(commit)\n",
    "\n",
    "    # pr\n",
    "    matched_ngrams = match_valid_ngrams(ngrams_pr)\n",
    "    if len(matched_ngrams) > 0:\n",
    "        pr['valid_ngrams'] = matched_ngrams\n",
    "        valid_pr_instances.append(pr)\n",
    "\n",
    "print(f\"valid commits: {len(valid_commit_instances)}\")\n",
    "print(f\"valid issues: {len(valid_issue_instances)}\")\n",
    "print(f\"valid prs: {len(valid_pr_instances)}\")\n",
    "\n",
    "save_data('valid_commits_' + AI_TOOL + '.jsonl', valid_commit_instances)\n",
    "save_data('valid_issues_' + AI_TOOL + '.jsonl', valid_issue_instances)\n",
    "save_data('valid_prs_' + AI_TOOL + '.jsonl', valid_pr_instances)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
